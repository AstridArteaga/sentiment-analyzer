{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "Hello\n",
      "Mr.\n",
      "Smith\n",
      ",\n",
      "how\n",
      "are\n",
      "you\n",
      "doing\n",
      "today\n",
      "?\n",
      "The\n",
      "weather\n",
      "is\n",
      "great\n",
      "and\n",
      "python\n",
      "is\n",
      "awesome\n",
      ".\n",
      "The\n",
      "sky\n",
      "is\n",
      "pinkish-blue\n",
      ".\n",
      "You\n",
      "should\n",
      "not\n",
      "eat\n",
      "cardboard\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download()\n",
    "# Separating by Sentence with Parragraph identifier.\n",
    "# Tokenizing: word tokenizers... Sentence tokenizers.\n",
    "# Lexicon and corpora.\n",
    "# corpora - body of text. ex: medical journals, presidential speeches, \n",
    "# English language.\n",
    "# Lexicon - words and their means.\n",
    "\n",
    "# investor-speak ... regular english-speak\n",
    "\n",
    "# investor speak 'bull' = 'someone who is positive about the market'.\n",
    "# english-speak 'bull' = scary animal you don't want running at you\n",
    "\n",
    "example_text = \"Hello Mr. Smith, how are you doing today? The weather is great and python is awesome. The sky is pinkish-blue. You should not eat cardboard\"\n",
    "\n",
    "#print(\"Tokenize by sentence:\")\n",
    "#print(sent_tokenize(example_text))\n",
    "#print(\"Tokenize by word: \")\n",
    "#print(word_tokenize(example_text))\n",
    "\n",
    "for i in word_tokenize(example_text):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['This', 'example', 'showing', 'stop', 'word', 'filtration', '.']\n['This', 'example', 'showing', 'stop', 'word', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tutorial 2. Stop Words. \n",
    "# Words that make you leave a text analysis. \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sentence = \"This is an example showing off stop word filtration.\"\n",
    "stop_words = set(stopwords.words(\"english\")) #Considerar que stopwords trabaja con diferentes lenguajes. \n",
    "words = word_tokenize(example_sentence)\n",
    "filtered_sentence = []\n",
    "for w in words:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "print(filtered_sentence)\n",
    "\n",
    "# One Liner.\n",
    "filtered_sentence_OL = [w for w in words if not w in stop_words]\n",
    "print(filtered_sentence_OL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n",
      "pythonli\n",
      "It\n",
      "is\n",
      "veri\n",
      "import\n",
      "to\n",
      "be\n",
      "pythonli\n",
      "while\n",
      "you\n",
      "are\n",
      "python\n",
      "with\n",
      "python\n",
      ".\n",
      "all\n",
      "python\n",
      "have\n",
      "python\n",
      "poorli\n",
      "at\n",
      "least\n",
      "onc\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# T3.Stemming\n",
    "# Takes the root stem of the word.\n",
    "# You can have different words with the same roots that mean the same.\n",
    "# Useful to economize space. \n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "example_words = [\"python\", \"pythoner\", \"pythoning\", \"pythoned\", \"pythonly\"]\n",
    "\n",
    "#for w in example_words:\n",
    "    #print(ps.stem(w))\n",
    "    \n",
    "new_text = \"It is very important to be pythonly while you are pythoning with python. All pythoners have pythoned poorly at least once.\"\n",
    "words = word_tokenize(new_text)\n",
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Z'), ('been', 'VBN'), ('falling', 'VBG'), ('for', 'IN'), ('a', 'DT'), ('dozen', 'NN'), ('years', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('row', 'NN'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('These', 'DT'), ('gains', 'NNS'), ('are', 'VBP'), ('evidence', 'NN'), ('of', 'IN'), ('a', 'DT'), ('quiet', 'JJ'), ('transformation', 'NN'), ('--', ':'), ('a', 'DT'), ('revolution', 'NN'), ('of', 'IN'), ('conscience', 'NN'), (',', ','), ('in', 'IN'), ('which', 'WDT'), ('a', 'DT'), ('rising', 'VBG'), ('generation', 'NN'), ('is', 'VBZ'), ('finding', 'VBG'), ('that', 'IN'), ('a', 'DT'), ('life', 'NN'), ('of', 'IN'), ('personal', 'JJ'), ('responsibility', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('life', 'NN'), ('of', 'IN'), ('fulfillment', 'NN'), ('.', '.')]\n",
      "[('Government', 'NNP'), ('has', 'VBZ'), ('played', 'VBN'), ('a', 'DT'), ('role', 'NN'), ('.', '.')]\n",
      "[('Wise', 'NNP'), ('policies', 'NNS'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('welfare', 'NN'), ('reform', 'NN'), ('and', 'CC'), ('drug', 'NN'), ('education', 'NN'), ('and', 'CC'), ('support', 'NN'), ('for', 'IN'), ('abstinence', 'NN'), ('and', 'CC'), ('adoption', 'NN'), ('have', 'VBP'), ('made', 'VBN'), ('a', 'DT'), ('difference', 'NN'), ('in', 'IN'), ('the', 'DT'), ('character', 'NN'), ('of', 'IN'), ('our', 'PRP$'), ('country', 'NN'), ('.', '.')]\n",
      "[('And', 'CC'), ('everyone', 'NN'), ('here', 'RB'), ('tonight', 'RB'), (',', ','), ('Democrat', 'NNP'), ('and', 'CC'), ('Republican', 'NNP'), (',', ','), ('has', 'VBZ'), ('a', 'DT'), ('right', 'NN'), ('to', 'TO'), ('be', 'VB'), ('proud', 'JJ'), ('of', 'IN'), ('this', 'DT'), ('record', 'NN'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('Yet', 'RB'), ('many', 'JJ'), ('Americans', 'NNPS'), (',', ','), ('especially', 'RB'), ('parents', 'NNS'), (',', ','), ('still', 'RB'), ('have', 'VBP'), ('deep', 'JJ'), ('concerns', 'NNS'), ('about', 'IN'), ('the', 'DT'), ('direction', 'NN'), ('of', 'IN'), ('our', 'PRP$'), ('culture', 'NN'), (',', ','), ('and', 'CC'), ('the', 'DT'), ('health', 'NN'), ('of', 'IN'), ('our', 'PRP$'), ('most', 'JJS'), ('basic', 'JJ'), ('institutions', 'NNS'), ('.', '.')]\n",
      "[('They', 'PRP'), (\"'re\", 'VBP'), ('concerned', 'VBN'), ('about', 'IN'), ('unethical', 'JJ'), ('conduct', 'NN'), ('by', 'IN'), ('public', 'JJ'), ('officials', 'NNS'), (',', ','), ('and', 'CC'), ('discouraged', 'VBN'), ('by', 'IN'), ('activist', 'NN'), ('courts', 'NNS'), ('that', 'WDT'), ('try', 'VBP'), ('to', 'TO'), ('redefine', 'VB'), ('marriage', 'NN'), ('.', '.')]\n",
      "[('They', 'PRP'), ('worry', 'VBP'), ('about', 'IN'), ('children', 'NNS'), ('in', 'IN'), ('our', 'PRP$'), ('society', 'NN'), ('who', 'WP'), ('need', 'VBP'), ('direction', 'NN'), ('and', 'CC'), ('love', 'NN'), (',', ','), ('and', 'CC'), ('about', 'IN'), ('fellow', 'JJ'), ('citizens', 'NNS'), ('still', 'RB'), ('displaced', 'VBN'), ('by', 'IN'), ('natural', 'JJ'), ('disaster', 'NN'), (',', ','), ('and', 'CC'), ('about', 'IN'), ('suffering', 'VBG'), ('caused', 'VBN'), ('by', 'IN'), ('treatable', 'JJ'), ('diseases', 'NNS'), ('.', '.')]\n",
      "[('As', 'IN'), ('we', 'PRP'), ('look', 'VBP'), ('at', 'IN'), ('these', 'DT'), ('challenges', 'NNS'), (',', ','), ('we', 'PRP'), ('must', 'MD'), ('never', 'RB'), ('give', 'VB'), ('in', 'IN'), ('to', 'TO'), ('the', 'DT'), ('belief', 'NN'), ('that', 'IN'), ('America', 'NNP'), ('is', 'VBZ'), ('in', 'IN'), ('decline', 'NN'), (',', ','), ('or', 'CC'), ('that', 'IN'), ('our', 'PRP$'), ('culture', 'NN'), ('is', 'VBZ'), ('doomed', 'VBN'), ('to', 'TO'), ('unravel', 'VB'), ('.', '.')]\n",
      "[('The', 'DT'), ('American', 'JJ'), ('people', 'NNS'), ('know', 'VBP'), ('better', 'JJR'), ('than', 'IN'), ('that', 'DT'), ('.', '.')]\n",
      "[('We', 'PRP'), ('have', 'VBP'), ('proven', 'VBN'), ('the', 'DT'), ('pessimists', 'NNS'), ('wrong', 'JJ'), ('before', 'RB'), ('--', ':'), ('and', 'CC'), ('we', 'PRP'), ('will', 'MD'), ('do', 'VB'), ('it', 'PRP'), ('again', 'RB'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('A', 'DT'), ('hopeful', 'JJ'), ('society', 'NN'), ('depends', 'VBZ'), ('on', 'IN'), ('courts', 'NNS'), ('that', 'IN'), ('deliver', 'VBP'), ('equal', 'JJ'), ('justice', 'NN'), ('under', 'IN'), ('the', 'DT'), ('law', 'NN'), ('.', '.')]\n",
      "[('The', 'DT'), ('Supreme', 'NNP'), ('Court', 'NNP'), ('now', 'RB'), ('has', 'VBZ'), ('two', 'CD'), ('superb', 'JJ'), ('new', 'JJ'), ('members', 'NNS'), ('--', ':'), ('new', 'JJ'), ('members', 'NNS'), ('on', 'IN'), ('its', 'PRP$'), ('bench', 'NN'), (':', ':'), ('Chief', 'JJ'), ('Justice', 'NNP'), ('John', 'NNP'), ('Roberts', 'NNP'), ('and', 'CC'), ('Justice', 'NNP'), ('Sam', 'NNP'), ('Alito', 'NNP'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('I', 'PRP'), ('thank', 'VBD'), ('the', 'DT'), ('Senate', 'NNP'), ('for', 'IN'), ('confirming', 'VBG'), ('both', 'DT'), ('of', 'IN'), ('them', 'PRP'), ('.', '.')]\n",
      "[('I', 'PRP'), ('will', 'MD'), ('continue', 'VB'), ('to', 'TO'), ('nominate', 'VB'), ('men', 'NNS'), ('and', 'CC'), ('women', 'NNS'), ('who', 'WP'), ('understand', 'VBP'), ('that', 'IN'), ('judges', 'NNS'), ('must', 'MD'), ('be', 'VB'), ('servants', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('law', 'NN'), (',', ','), ('and', 'CC'), ('not', 'RB'), ('legislate', 'VB'), ('from', 'IN'), ('the', 'DT'), ('bench', 'NN'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('Today', 'NN'), ('marks', 'VBZ'), ('the', 'DT'), ('official', 'JJ'), ('retirement', 'NN'), ('of', 'IN'), ('a', 'DT'), ('very', 'RB'), ('special', 'JJ'), ('American', 'NNP'), ('.', '.')]\n",
      "[('For', 'IN'), ('24', 'CD'), ('years', 'NNS'), ('of', 'IN'), ('faithful', 'JJ'), ('service', 'NN'), ('to', 'TO'), ('our', 'PRP$'), ('nation', 'NN'), (',', ','), ('the', 'DT'), ('United', 'NNP'), ('States', 'NNPS'), ('is', 'VBZ'), ('grateful', 'JJ'), ('to', 'TO'), ('Justice', 'NNP'), ('Sandra', 'NNP'), ('Day', 'NNP'), (\"O'Connor\", 'NNP'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('A', 'DT'), ('hopeful', 'JJ'), ('society', 'NN'), ('has', 'VBZ'), ('institutions', 'NNS'), ('of', 'IN'), ('science', 'NN'), ('and', 'CC'), ('medicine', 'NN'), ('that', 'WDT'), ('do', 'VBP'), ('not', 'RB'), ('cut', 'VB'), ('ethical', 'JJ'), ('corners', 'NNS'), (',', ','), ('and', 'CC'), ('that', 'IN'), ('recognize', 'VBP'), ('the', 'DT'), ('matchless', 'NN'), ('value', 'NN'), ('of', 'IN'), ('every', 'DT'), ('life', 'NN'), ('.', '.')]\n",
      "[('Tonight', 'NNP'), ('I', 'PRP'), ('ask', 'VBP'), ('you', 'PRP'), ('to', 'TO'), ('pass', 'VB'), ('legislation', 'NN'), ('to', 'TO'), ('prohibit', 'VB'), ('the', 'DT'), ('most', 'RBS'), ('egregious', 'JJ'), ('abuses', 'NNS'), ('of', 'IN'), ('medical', 'JJ'), ('research', 'NN'), (':', ':'), ('human', 'JJ'), ('cloning', 'VBG'), ('in', 'IN'), ('all', 'DT'), ('its', 'PRP$'), ('forms', 'NNS'), (',', ','), ('creating', 'VBG'), ('or', 'CC'), ('implanting', 'VBG'), ('embryos', 'NN'), ('for', 'IN'), ('experiments', 'NNS'), (',', ','), ('creating', 'VBG'), ('human-animal', 'JJ'), ('hybrids', 'NNS'), (',', ','), ('and', 'CC'), ('buying', 'NN'), (',', ','), ('selling', 'NN'), (',', ','), ('or', 'CC'), ('patenting', 'VBG'), ('human', 'JJ'), ('embryos', 'NN'), ('.', '.')]\n",
      "[('Human', 'NNP'), ('life', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('gift', 'NN'), ('from', 'IN'), ('our', 'PRP$'), ('Creator', 'NNP'), ('--', ':'), ('and', 'CC'), ('that', 'IN'), ('gift', 'NN'), ('should', 'MD'), ('never', 'RB'), ('be', 'VB'), ('discarded', 'VBN'), (',', ','), ('devalued', 'VBD'), ('or', 'CC'), ('put', 'VB'), ('up', 'RP'), ('for', 'IN'), ('sale', 'NN'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('A', 'DT'), ('hopeful', 'JJ'), ('society', 'NN'), ('expects', 'VBZ'), ('elected', 'VBN'), ('officials', 'NNS'), ('to', 'TO'), ('uphold', 'VB'), ('the', 'DT'), ('public', 'JJ'), ('trust', 'NN'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('Honorable', 'JJ'), ('people', 'NNS'), ('in', 'IN'), ('both', 'DT'), ('parties', 'NNS'), ('are', 'VBP'), ('working', 'VBG'), ('on', 'IN'), ('reforms', 'NNS'), ('to', 'TO'), ('strengthen', 'VB'), ('the', 'DT'), ('ethical', 'JJ'), ('standards', 'NNS'), ('of', 'IN'), ('Washington', 'NNP'), ('--', ':'), ('I', 'PRP'), ('support', 'VBP'), ('your', 'PRP$'), ('efforts', 'NNS'), ('.', '.')]\n",
      "[('Each', 'DT'), ('of', 'IN'), ('us', 'PRP'), ('has', 'VBZ'), ('made', 'VBN'), ('a', 'DT'), ('pledge', 'NN'), ('to', 'TO'), ('be', 'VB'), ('worthy', 'JJ'), ('of', 'IN'), ('public', 'JJ'), ('responsibility', 'NN'), ('--', ':'), ('and', 'CC'), ('that', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('pledge', 'NN'), ('we', 'PRP'), ('must', 'MD'), ('never', 'RB'), ('forget', 'VB'), (',', ','), ('never', 'RB'), ('dismiss', 'NN'), (',', ','), ('and', 'CC'), ('never', 'RB'), ('betray', 'NN'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('As', 'IN'), ('we', 'PRP'), ('renew', 'VBP'), ('the', 'DT'), ('promise', 'NN'), ('of', 'IN'), ('our', 'PRP$'), ('institutions', 'NNS'), (',', ','), ('let', 'VB'), ('us', 'PRP'), ('also', 'RB'), ('show', 'VBP'), ('the', 'DT'), ('character', 'NN'), ('of', 'IN'), ('America', 'NNP'), ('in', 'IN'), ('our', 'PRP$'), ('compassion', 'NN'), ('and', 'CC'), ('care', 'NN'), ('for', 'IN'), ('one', 'CD'), ('another', 'DT'), ('.', '.')]\n",
      "[('A', 'DT'), ('hopeful', 'JJ'), ('society', 'NN'), ('gives', 'VBZ'), ('special', 'JJ'), ('attention', 'NN'), ('to', 'TO'), ('children', 'NNS'), ('who', 'WP'), ('lack', 'VBP'), ('direction', 'NN'), ('and', 'CC'), ('love', 'NN'), ('.', '.')]\n",
      "[('Through', 'IN'), ('the', 'DT'), ('Helping', 'NNP'), ('America', 'NNP'), (\"'s\", 'POS'), ('Youth', 'NNP'), ('Initiative', 'NNP'), (',', ','), ('we', 'PRP'), ('are', 'VBP'), ('encouraging', 'VBG'), ('caring', 'VBG'), ('adults', 'NNS'), ('to', 'TO'), ('get', 'VB'), ('involved', 'VBN'), ('in', 'IN'), ('the', 'DT'), ('life', 'NN'), ('of', 'IN'), ('a', 'DT'), ('child', 'NN'), ('--', ':'), ('and', 'CC'), ('this', 'DT'), ('good', 'JJ'), ('work', 'NN'), ('is', 'VBZ'), ('being', 'VBG'), ('led', 'VBN'), ('by', 'IN'), ('our', 'PRP$'), ('First', 'NNP'), ('Lady', 'NNP'), (',', ','), ('Laura', 'NNP'), ('Bush', 'NNP'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('This', 'DT'), ('year', 'NN'), ('we', 'PRP'), ('will', 'MD'), ('add', 'VB'), ('resources', 'NNS'), ('to', 'TO'), ('encourage', 'VB'), ('young', 'JJ'), ('people', 'NNS'), ('to', 'TO'), ('stay', 'VB'), ('in', 'IN'), ('school', 'NN'), (',', ','), ('so', 'RB'), ('more', 'JJR'), ('of', 'IN'), ('America', 'NNP'), (\"'s\", 'POS'), ('youth', 'NN'), ('can', 'MD'), ('raise', 'VB'), ('their', 'PRP$'), ('sights', 'NNS'), ('and', 'CC'), ('achieve', 'VBP'), ('their', 'PRP$'), ('dreams', 'NNS'), ('.', '.')]\n",
      "[('A', 'DT'), ('hopeful', 'JJ'), ('society', 'NN'), ('comes', 'VBZ'), ('to', 'TO'), ('the', 'DT'), ('aid', 'NN'), ('of', 'IN'), ('fellow', 'JJ'), ('citizens', 'NNS'), ('in', 'IN'), ('times', 'NNS'), ('of', 'IN'), ('suffering', 'NN'), ('and', 'CC'), ('emergency', 'NN'), ('--', ':'), ('and', 'CC'), ('stays', 'NNS'), ('at', 'IN'), ('it', 'PRP'), ('until', 'IN'), ('they', 'PRP'), (\"'re\", 'VBP'), ('back', 'RB'), ('on', 'IN'), ('their', 'PRP$'), ('feet', 'NNS'), ('.', '.')]\n",
      "[('So', 'RB'), ('far', 'RB'), ('the', 'DT'), ('federal', 'JJ'), ('government', 'NN'), ('has', 'VBZ'), ('committed', 'VBN'), ('$', '$'), ('85', 'CD'), ('billion', 'CD'), ('to', 'TO'), ('the', 'DT'), ('people', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Gulf', 'NNP'), ('Coast', 'NNP'), ('and', 'CC'), ('New', 'NNP'), ('Orleans', 'NNP'), ('.', '.')]\n",
      "[('We', 'PRP'), (\"'re\", 'VBP'), ('removing', 'VBG'), ('debris', 'NN'), ('and', 'CC'), ('repairing', 'NN'), ('highways', 'NNS'), ('and', 'CC'), ('rebuilding', 'VBG'), ('stronger', 'JJR'), ('levees', 'NNS'), ('.', '.')]\n",
      "[('We', 'PRP'), (\"'re\", 'VBP'), ('providing', 'VBG'), ('business', 'NN'), ('loans', 'NNS'), ('and', 'CC'), ('housing', 'NN'), ('assistance', 'NN'), ('.', '.')]\n",
      "[('Yet', 'RB'), ('as', 'IN'), ('we', 'PRP'), ('meet', 'VBP'), ('these', 'DT'), ('immediate', 'JJ'), ('needs', 'NNS'), (',', ','), ('we', 'PRP'), ('must', 'MD'), ('also', 'RB'), ('address', 'VB'), ('deeper', 'JJR'), ('challenges', 'NNS'), ('that', 'WDT'), ('existed', 'VBD'), ('before', 'IN'), ('the', 'DT'), ('storm', 'NN'), ('arrived', 'VBD'), ('.', '.')]\n",
      "[('In', 'IN'), ('New', 'NNP'), ('Orleans', 'NNP'), ('and', 'CC'), ('in', 'IN'), ('other', 'JJ'), ('places', 'NNS'), (',', ','), ('many', 'JJ'), ('of', 'IN'), ('our', 'PRP$'), ('fellow', 'JJ'), ('citizens', 'NNS'), ('have', 'VBP'), ('felt', 'VBN'), ('excluded', 'VBN'), ('from', 'IN'), ('the', 'DT'), ('promise', 'NN'), ('of', 'IN'), ('our', 'PRP$'), ('country', 'NN'), ('.', '.')]\n",
      "[('The', 'DT'), ('answer', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('only', 'RB'), ('temporary', 'JJ'), ('relief', 'NN'), (',', ','), ('but', 'CC'), ('schools', 'NNS'), ('that', 'WDT'), ('teach', 'VBP'), ('every', 'DT'), ('child', 'NN'), (',', ','), ('and', 'CC'), ('job', 'NN'), ('skills', 'NNS'), ('that', 'IN'), ('bring', 'VBG'), ('upward', 'JJ'), ('mobility', 'NN'), (',', ','), ('and', 'CC'), ('more', 'JJR'), ('opportunities', 'NNS'), ('to', 'TO'), ('own', 'VB'), ('a', 'DT'), ('home', 'NN'), ('and', 'CC'), ('start', 'VB'), ('a', 'DT'), ('business', 'NN'), ('.', '.')]\n",
      "[('As', 'IN'), ('we', 'PRP'), ('recover', 'VBP'), ('from', 'IN'), ('a', 'DT'), ('disaster', 'NN'), (',', ','), ('let', 'VB'), ('us', 'PRP'), ('also', 'RB'), ('work', 'NN'), ('for', 'IN'), ('the', 'DT'), ('day', 'NN'), ('when', 'WRB'), ('all', 'DT'), ('Americans', 'NNPS'), ('are', 'VBP'), ('protected', 'VBN'), ('by', 'IN'), ('justice', 'NN'), (',', ','), ('equal', 'JJ'), ('in', 'IN'), ('hope', 'NN'), (',', ','), ('and', 'CC'), ('rich', 'JJ'), ('in', 'IN'), ('opportunity', 'NN'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('A', 'DT'), ('hopeful', 'JJ'), ('society', 'NN'), ('acts', 'NNS'), ('boldly', 'RB'), ('to', 'TO'), ('fight', 'VB'), ('diseases', 'NNS'), ('like', 'IN'), ('HIV/AIDS', 'NNP'), (',', ','), ('which', 'WDT'), ('can', 'MD'), ('be', 'VB'), ('prevented', 'VBN'), (',', ','), ('and', 'CC'), ('treated', 'VBD'), (',', ','), ('and', 'CC'), ('defeated', 'VBD'), ('.', '.')]\n",
      "[('More', 'JJR'), ('than', 'IN'), ('a', 'DT'), ('million', 'CD'), ('Americans', 'NNPS'), ('live', 'VBP'), ('with', 'IN'), ('HIV', 'NNP'), (',', ','), ('and', 'CC'), ('half', 'NN'), ('of', 'IN'), ('all', 'DT'), ('AIDS', 'NNP'), ('cases', 'NNS'), ('occur', 'VBP'), ('among', 'IN'), ('African', 'JJ'), ('Americans', 'NNPS'), ('.', '.')]\n",
      "[('I', 'PRP'), ('ask', 'VBP'), ('Congress', 'NNP'), ('to', 'TO'), ('reform', 'VB'), ('and', 'CC'), ('reauthorize', 'VB'), ('the', 'DT'), ('Ryan', 'NNP'), ('White', 'NNP'), ('Act', 'NNP'), (',', ','), ('and', 'CC'), ('provide', 'VB'), ('new', 'JJ'), ('funding', 'NN'), ('to', 'TO'), ('states', 'NNS'), (',', ','), ('so', 'IN'), ('we', 'PRP'), ('end', 'VBP'), ('the', 'DT'), ('waiting', 'NN'), ('lists', 'NNS'), ('for', 'IN'), ('AIDS', 'NNP'), ('medicines', 'NNS'), ('in', 'IN'), ('America', 'NNP'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('We', 'PRP'), ('will', 'MD'), ('also', 'RB'), ('lead', 'VB'), ('a', 'DT'), ('nationwide', 'JJ'), ('effort', 'NN'), (',', ','), ('working', 'VBG'), ('closely', 'RB'), ('with', 'IN'), ('African', 'JJ'), ('American', 'JJ'), ('churches', 'NNS'), ('and', 'CC'), ('faith-based', 'JJ'), ('groups', 'NNS'), (',', ','), ('to', 'TO'), ('deliver', 'VB'), ('rapid', 'JJ'), ('HIV', 'NNP'), ('tests', 'NNS'), ('to', 'TO'), ('millions', 'NNS'), (',', ','), ('end', 'VBP'), ('the', 'DT'), ('stigma', 'NN'), ('of', 'IN'), ('AIDS', 'NNP'), (',', ','), ('and', 'CC'), ('come', 'VB'), ('closer', 'JJR'), ('to', 'TO'), ('the', 'DT'), ('day', 'NN'), ('when', 'WRB'), ('there', 'EX'), ('are', 'VBP'), ('no', 'DT'), ('new', 'JJ'), ('infections', 'NNS'), ('in', 'IN'), ('America', 'NNP'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
      "[('Fellow', 'NNP'), ('citizens', 'NNS'), (',', ','), ('we', 'PRP'), (\"'ve\", 'VBP'), ('been', 'VBN'), ('called', 'VBN'), ('to', 'TO'), ('leadership', 'NN'), ('in', 'IN'), ('a', 'DT'), ('period', 'NN'), ('of', 'IN'), ('consequence', 'NN'), ('.', '.')]\n",
      "[('We', 'PRP'), (\"'ve\", 'VBP'), ('entered', 'VBN'), ('a', 'DT'), ('great', 'JJ'), ('ideological', 'JJ'), ('conflict', 'NN'), ('we', 'PRP'), ('did', 'VBD'), ('nothing', 'NN'), ('to', 'TO'), ('invite', 'VB'), ('.', '.')]\n",
      "[('We', 'PRP'), ('see', 'VBP'), ('great', 'JJ'), ('changes', 'NNS'), ('in', 'IN'), ('science', 'NN'), ('and', 'CC'), ('commerce', 'NN'), ('that', 'WDT'), ('will', 'MD'), ('influence', 'VB'), ('all', 'DT'), ('our', 'PRP$'), ('lives', 'NNS'), ('.', '.')]\n",
      "[('Sometimes', 'RB'), ('it', 'PRP'), ('can', 'MD'), ('seem', 'VB'), ('that', 'DT'), ('history', 'NN'), ('is', 'VBZ'), ('turning', 'VBG'), ('in', 'IN'), ('a', 'DT'), ('wide', 'JJ'), ('arc', 'NN'), (',', ','), ('toward', 'IN'), ('an', 'DT'), ('unknown', 'JJ'), ('shore', 'NN'), ('.', '.')]\n",
      "[('Yet', 'CC'), ('the', 'DT'), ('destination', 'NN'), ('of', 'IN'), ('history', 'NN'), ('is', 'VBZ'), ('determined', 'VBN'), ('by', 'IN'), ('human', 'JJ'), ('action', 'NN'), (',', ','), ('and', 'CC'), ('every', 'DT'), ('great', 'JJ'), ('movement', 'NN'), ('of', 'IN'), ('history', 'NN'), ('comes', 'VBZ'), ('to', 'TO'), ('a', 'DT'), ('point', 'NN'), ('of', 'IN'), ('choosing', 'NN'), ('.', '.')]\n",
      "[('Lincoln', 'NNP'), ('could', 'MD'), ('have', 'VB'), ('accepted', 'VBN'), ('peace', 'NN'), ('at', 'IN'), ('the', 'DT'), ('cost', 'NN'), ('of', 'IN'), ('disunity', 'NN'), ('and', 'CC'), ('continued', 'JJ'), ('slavery', 'NN'), ('.', '.')]\n",
      "[('Martin', 'NNP'), ('Luther', 'NNP'), ('King', 'NNP'), ('could', 'MD'), ('have', 'VB'), ('stopped', 'VBN'), ('at', 'IN'), ('Birmingham', 'NNP'), ('or', 'CC'), ('at', 'IN'), ('Selma', 'NNP'), (',', ','), ('and', 'CC'), ('achieved', 'VBD'), ('only', 'RB'), ('half', 'PDT'), ('a', 'DT'), ('victory', 'NN'), ('over', 'IN'), ('segregation', 'NN'), ('.', '.')]\n",
      "[('The', 'DT'), ('United', 'NNP'), ('States', 'NNPS'), ('could', 'MD'), ('have', 'VB'), ('accepted', 'VBN'), ('the', 'DT'), ('permanent', 'JJ'), ('division', 'NN'), ('of', 'IN'), ('Europe', 'NNP'), (',', ','), ('and', 'CC'), ('been', 'VBN'), ('complicit', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('oppression', 'NN'), ('of', 'IN'), ('others', 'NNS'), ('.', '.')]\n",
      "[('Today', 'NN'), (',', ','), ('having', 'VBG'), ('come', 'VBN'), ('far', 'RB'), ('in', 'IN'), ('our', 'PRP$'), ('own', 'JJ'), ('historical', 'JJ'), ('journey', 'NN'), (',', ','), ('we', 'PRP'), ('must', 'MD'), ('decide', 'VB'), (':', ':'), ('Will', 'MD'), ('we', 'PRP'), ('turn', 'VB'), ('back', 'RP'), (',', ','), ('or', 'CC'), ('finish', 'VB'), ('well', 'RB'), ('?', '.')]\n",
      "[('Before', 'IN'), ('history', 'NN'), ('is', 'VBZ'), ('written', 'VBN'), ('down', 'RP'), ('in', 'IN'), ('books', 'NNS'), (',', ','), ('it', 'PRP'), ('is', 'VBZ'), ('written', 'VBN'), ('in', 'IN'), ('courage', 'NN'), ('.', '.')]\n",
      "[('Like', 'IN'), ('Americans', 'NNPS'), ('before', 'IN'), ('us', 'PRP'), (',', ','), ('we', 'PRP'), ('will', 'MD'), ('show', 'VB'), ('that', 'DT'), ('courage', 'NN'), ('and', 'CC'), ('we', 'PRP'), ('will', 'MD'), ('finish', 'VB'), ('well', 'RB'), ('.', '.')]\n",
      "[('We', 'PRP'), ('will', 'MD'), ('lead', 'VB'), ('freedom', 'NN'), (\"'s\", 'POS'), ('advance', 'NN'), ('.', '.')]\n",
      "[('We', 'PRP'), ('will', 'MD'), ('compete', 'VB'), ('and', 'CC'), ('excel', 'VB'), ('in', 'IN'), ('the', 'DT'), ('global', 'JJ'), ('economy', 'NN'), ('.', '.')]\n",
      "[('We', 'PRP'), ('will', 'MD'), ('renew', 'VB'), ('the', 'DT'), ('defining', 'VBG'), ('moral', 'JJ'), ('commitments', 'NNS'), ('of', 'IN'), ('this', 'DT'), ('land', 'NN'), ('.', '.')]\n",
      "[('And', 'CC'), ('so', 'RB'), ('we', 'PRP'), ('move', 'VBP'), ('forward', 'RB'), ('--', ':'), ('optimistic', 'JJ'), ('about', 'IN'), ('our', 'PRP$'), ('country', 'NN'), (',', ','), ('faithful', 'JJ'), ('to', 'TO'), ('its', 'PRP$'), ('cause', 'NN'), (',', ','), ('and', 'CC'), ('confident', 'NN'), ('of', 'IN'), ('the', 'DT'), ('victories', 'NNS'), ('to', 'TO'), ('come', 'VB'), ('.', '.')]\n",
      "[('May', 'NNP'), ('God', 'NNP'), ('bless', 'NN'), ('America', 'NNP'), ('.', '.')]\n",
      "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n"
     ]
    }
   ],
   "source": [
    "# Part 4. Part of Speech tagging.\n",
    "#Creates tuples with the word and the parts of speech. \n",
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer #Unsupervised learning tokenizer.\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try: \n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            \n",
    "            print(tagged)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "  of/IN\n",
      "  producing/VBG\n",
      "  ethanol/NN\n",
      "  ,/,\n",
      "  not/RB\n",
      "  just/RB\n",
      "  from/IN\n",
      "  corn/NN\n",
      "  ,/,\n",
      "  but/CC\n",
      "  from/IN\n",
      "  wood/NN\n",
      "  chips/NNS\n",
      "  and/CC\n",
      "  stalks/NNS\n",
      "  ,/,\n",
      "  or/CC\n",
      "  switch/VB\n",
      "  grass/NN\n",
      "  ./.)\n",
      "(S\n",
      "  Our/PRP$\n",
      "  goal/NN\n",
      "  is/VBZ\n",
      "  to/TO\n",
      "  make/VB\n",
      "  this/DT\n",
      "  new/JJ\n",
      "  kind/NN\n",
      "  of/IN\n",
      "  ethanol/JJ\n",
      "  practical/JJ\n",
      "  and/CC\n",
      "  competitive/JJ\n",
      "  within/IN\n",
      "  six/CD\n",
      "  years/NNS\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  Breakthroughs/NNS\n",
      "  on/IN\n",
      "  this/DT\n",
      "  and/CC\n",
      "  other/JJ\n",
      "  new/JJ\n",
      "  technologies/NNS\n",
      "  will/MD\n",
      "  help/VB\n",
      "  us/PRP\n",
      "  reach/VB\n",
      "  another/DT\n",
      "  great/JJ\n",
      "  goal/NN\n",
      "  :/:\n",
      "  to/TO\n",
      "  replace/VB\n",
      "  more/JJR\n",
      "  than/IN\n",
      "  75/CD\n",
      "  percent/NN\n",
      "  of/IN\n",
      "  our/PRP$\n",
      "  oil/NN\n",
      "  imports/NNS\n",
      "  from/IN\n",
      "  the/DT\n",
      "  (Chunk Middle/NNP East/NNP)\n",
      "  by/IN\n",
      "  2025/CD\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  By/IN\n",
      "  applying/VBG\n",
      "  the/DT\n",
      "  talent/NN\n",
      "  and/CC\n",
      "  technology/NN\n",
      "  of/IN\n",
      "  (Chunk America/NNP)\n",
      "  ,/,\n",
      "  this/DT\n",
      "  country/NN\n",
      "  can/MD\n",
      "  dramatically/RB\n",
      "  improve/VB\n",
      "  our/PRP$\n",
      "  environment/NN\n",
      "  ,/,\n",
      "  move/VB\n",
      "  beyond/IN\n",
      "  a/DT\n",
      "  petroleum-based/JJ\n",
      "  economy/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  make/VB\n",
      "  our/PRP$\n",
      "  dependence/NN\n",
      "  on/IN\n",
      "  (Chunk Middle/NNP Eastern/NNP oil/NN)\n",
      "  a/DT\n",
      "  thing/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  past/NN\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  And/CC\n",
      "  to/TO\n",
      "  (Chunk keep/VB America/NNP)\n",
      "  competitive/JJ\n",
      "  ,/,\n",
      "  one/CD\n",
      "  commitment/NN\n",
      "  is/VBZ\n",
      "  necessary/JJ\n",
      "  above/IN\n",
      "  all/DT\n",
      "  :/:\n",
      "  We/PRP\n",
      "  must/MD\n",
      "  continue/VB\n",
      "  to/TO\n",
      "  lead/VB\n",
      "  the/DT\n",
      "  world/NN\n",
      "  in/IN\n",
      "  human/JJ\n",
      "  talent/NN\n",
      "  and/CC\n",
      "  creativity/NN\n",
      "  ./.)\n",
      "(S\n",
      "  Our/PRP$\n",
      "  greatest/JJS\n",
      "  advantage/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  world/NN\n",
      "  has/VBZ\n",
      "  always/RB\n",
      "  been/VBN\n",
      "  our/PRP$\n",
      "  educated/VBN\n",
      "  ,/,\n",
      "  hardworking/VBG\n",
      "  ,/,\n",
      "  ambitious/JJ\n",
      "  people/NNS\n",
      "  --/:\n",
      "  and/CC\n",
      "  we/PRP\n",
      "  're/VBP\n",
      "  going/VBG\n",
      "  to/TO\n",
      "  keep/VB\n",
      "  that/DT\n",
      "  edge/NN\n",
      "  ./.)\n",
      "(S\n",
      "  Tonight/NN\n",
      "  I/PRP\n",
      "  announce/VBP\n",
      "  an/DT\n",
      "  American/JJ\n",
      "  (Chunk Competitiveness/NNP Initiative/NNP)\n",
      "  ,/,\n",
      "  to/TO\n",
      "  encourage/VB\n",
      "  innovation/NN\n",
      "  throughout/IN\n",
      "  our/PRP$\n",
      "  economy/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  to/TO\n",
      "  give/VB\n",
      "  our/PRP$\n",
      "  nation/NN\n",
      "  's/POS\n",
      "  children/NNS\n",
      "  a/DT\n",
      "  firm/NN\n",
      "  grounding/VBG\n",
      "  in/IN\n",
      "  math/NN\n",
      "  and/CC\n",
      "  science/NN\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  First/RB\n",
      "  ,/,\n",
      "  I/PRP\n",
      "  propose/VBP\n",
      "  to/TO\n",
      "  double/VB\n",
      "  the/DT\n",
      "  federal/JJ\n",
      "  commitment/NN\n",
      "  to/TO\n",
      "  the/DT\n",
      "  most/RBS\n",
      "  critical/JJ\n",
      "  basic/JJ\n",
      "  research/NN\n",
      "  programs/NNS\n",
      "  in/IN\n",
      "  the/DT\n",
      "  physical/JJ\n",
      "  sciences/NNS\n",
      "  over/IN\n",
      "  the/DT\n",
      "  next/JJ\n",
      "  10/CD\n",
      "  years/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  This/DT\n",
      "  funding/NN\n",
      "  will/MD\n",
      "  support/VB\n",
      "  the/DT\n",
      "  work/NN\n",
      "  of/IN\n",
      "  (Chunk America/NNP)\n",
      "  's/POS\n",
      "  most/RBS\n",
      "  creative/JJ\n",
      "  minds/NNS\n",
      "  as/IN\n",
      "  they/PRP\n",
      "  explore/VBP\n",
      "  promising/VBG\n",
      "  areas/NNS\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  nanotechnology/NN\n",
      "  ,/,\n",
      "  supercomputing/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  alternative/JJ\n",
      "  energy/NN\n",
      "  sources/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  Second/JJ\n",
      "  ,/,\n",
      "  I/PRP\n",
      "  propose/VBP\n",
      "  to/TO\n",
      "  make/VB\n",
      "  permanent/JJ\n",
      "  the/DT\n",
      "  research/NN\n",
      "  and/CC\n",
      "  development/NN\n",
      "  tax/NN\n",
      "  credit/NN\n",
      "  --/:\n",
      "  (/(\n",
      "  applause/NN\n",
      "  )/)\n",
      "  --/:\n",
      "  to/TO\n",
      "  encourage/VB\n",
      "  bolder/VB\n",
      "  private-sector/JJ\n",
      "  initiatives/NNS\n",
      "  in/IN\n",
      "  technology/NN\n",
      "  ./.)\n",
      "(S\n",
      "  With/IN\n",
      "  more/JJR\n",
      "  research/NN\n",
      "  in/IN\n",
      "  both/CC\n",
      "  the/DT\n",
      "  public/NN\n",
      "  and/CC\n",
      "  private/JJ\n",
      "  sectors/NNS\n",
      "  ,/,\n",
      "  we/PRP\n",
      "  will/MD\n",
      "  improve/VB\n",
      "  our/PRP$\n",
      "  quality/NN\n",
      "  of/IN\n",
      "  life/NN\n",
      "  --/:\n",
      "  and/CC\n",
      "  ensure/VB\n",
      "  that/DT\n",
      "  (Chunk America/NNP)\n",
      "  will/MD\n",
      "  lead/VB\n",
      "  the/DT\n",
      "  world/NN\n",
      "  in/IN\n",
      "  opportunity/NN\n",
      "  and/CC\n",
      "  innovation/NN\n",
      "  for/IN\n",
      "  decades/NNS\n",
      "  to/TO\n",
      "  come/VB\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  (Chunk Third/NNP)\n",
      "  ,/,\n",
      "  we/PRP\n",
      "  need/VBP\n",
      "  to/TO\n",
      "  encourage/VB\n",
      "  children/NNS\n",
      "  to/TO\n",
      "  take/VB\n",
      "  more/JJR\n",
      "  math/NN\n",
      "  and/CC\n",
      "  science/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  to/TO\n",
      "  make/VB\n",
      "  sure/JJ\n",
      "  those/DT\n",
      "  courses/NNS\n",
      "  are/VBP\n",
      "  rigorous/JJ\n",
      "  enough/RB\n",
      "  to/TO\n",
      "  compete/VB\n",
      "  with/IN\n",
      "  other/JJ\n",
      "  nations/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  We/PRP\n",
      "  've/VBP\n",
      "  made/VBN\n",
      "  a/DT\n",
      "  good/JJ\n",
      "  start/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  early/JJ\n",
      "  grades/NNS\n",
      "  with/IN\n",
      "  the/DT\n",
      "  (Chunk No/NNP Child/NNP Left/NNP Behind/NNP Act/NNP)\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  is/VBZ\n",
      "  raising/VBG\n",
      "  standards/NNS\n",
      "  and/CC\n",
      "  lifting/VBG\n",
      "  test/NN\n",
      "  scores/NNS\n",
      "  across/IN\n",
      "  our/PRP$\n",
      "  country/NN\n",
      "  ./.)\n",
      "(S\n",
      "  (Chunk Tonight/NNP)\n",
      "  I/PRP\n",
      "  propose/VBP\n",
      "  to/TO\n",
      "  train/VB\n",
      "  70,000/CD\n",
      "  high/JJ\n",
      "  school/NN\n",
      "  teachers/NNS\n",
      "  to/TO\n",
      "  lead/VB\n",
      "  advanced-placement/JJ\n",
      "  courses/NNS\n",
      "  in/IN\n",
      "  math/NN\n",
      "  and/CC\n",
      "  science/NN\n",
      "  ,/,\n",
      "  bring/VBG\n",
      "  30,000/CD\n",
      "  math/NN\n",
      "  and/CC\n",
      "  science/NN\n",
      "  professionals/NNS\n",
      "  to/TO\n",
      "  teach/VB\n",
      "  in/IN\n",
      "  classrooms/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  give/VB\n",
      "  early/JJ\n",
      "  help/NN\n",
      "  to/TO\n",
      "  students/NNS\n",
      "  who/WP\n",
      "  struggle/VBP\n",
      "  with/IN\n",
      "  math/NN\n",
      "  ,/,\n",
      "  so/IN\n",
      "  they/PRP\n",
      "  have/VBP\n",
      "  a/DT\n",
      "  better/JJR\n",
      "  chance/NN\n",
      "  at/IN\n",
      "  good/JJ\n",
      "  ,/,\n",
      "  high-wage/JJ\n",
      "  jobs/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  If/IN\n",
      "  we/PRP\n",
      "  ensure/VB\n",
      "  that/IN\n",
      "  (Chunk America/NNP)\n",
      "  's/POS\n",
      "  children/NNS\n",
      "  succeed/VB\n",
      "  in/IN\n",
      "  life/NN\n",
      "  ,/,\n",
      "  they/PRP\n",
      "  will/MD\n",
      "  ensure/VB\n",
      "  that/IN\n",
      "  (Chunk America/NNP)\n",
      "  succeeds/VBZ\n",
      "  in/IN\n",
      "  the/DT\n",
      "  world/NN\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  Preparing/VBG\n",
      "  our/PRP$\n",
      "  nation/NN\n",
      "  to/TO\n",
      "  compete/VB\n",
      "  in/IN\n",
      "  the/DT\n",
      "  world/NN\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  goal/NN\n",
      "  that/IN\n",
      "  all/DT\n",
      "  of/IN\n",
      "  us/PRP\n",
      "  can/MD\n",
      "  share/NN\n",
      "  ./.)\n",
      "(S\n",
      "  I/PRP\n",
      "  urge/VBP\n",
      "  you/PRP\n",
      "  to/TO\n",
      "  support/VB\n",
      "  the/DT\n",
      "  American/JJ\n",
      "  (Chunk Competitiveness/NNP Initiative/NNP)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  together/RB\n",
      "  we/PRP\n",
      "  will/MD\n",
      "  show/VB\n",
      "  the/DT\n",
      "  world/NN\n",
      "  what/WP\n",
      "  the/DT\n",
      "  American/JJ\n",
      "  people/NNS\n",
      "  can/MD\n",
      "  achieve/VB\n",
      "  ./.)\n",
      "(S\n",
      "  (Chunk America/NNP)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  great/JJ\n",
      "  force/NN\n",
      "  for/IN\n",
      "  freedom/NN\n",
      "  and/CC\n",
      "  prosperity/NN\n",
      "  ./.)\n",
      "(S\n",
      "  Yet/RB\n",
      "  our/PRP$\n",
      "  greatness/NN\n",
      "  is/VBZ\n",
      "  not/RB\n",
      "  measured/VBN\n",
      "  in/IN\n",
      "  power/NN\n",
      "  or/CC\n",
      "  luxuries/NNS\n",
      "  ,/,\n",
      "  but/CC\n",
      "  by/IN\n",
      "  who/WP\n",
      "  we/PRP\n",
      "  are/VBP\n",
      "  and/CC\n",
      "  how/WRB\n",
      "  we/PRP\n",
      "  treat/VBP\n",
      "  one/CD\n",
      "  another/DT\n",
      "  ./.)\n",
      "(S\n",
      "  So/IN\n",
      "  we/PRP\n",
      "  strive/VBP\n",
      "  to/TO\n",
      "  be/VB\n",
      "  a/DT\n",
      "  compassionate/NN\n",
      "  ,/,\n",
      "  decent/NN\n",
      "  ,/,\n",
      "  hopeful/JJ\n",
      "  society/NN\n",
      "  ./.)\n",
      "(S\n",
      "  In/IN\n",
      "  recent/JJ\n",
      "  years/NNS\n",
      "  ,/,\n",
      "  (Chunk America/NNP)\n",
      "  has/VBZ\n",
      "  become/VBN\n",
      "  a/DT\n",
      "  more/RBR\n",
      "  hopeful/JJ\n",
      "  nation/NN\n",
      "  ./.)\n",
      "(S\n",
      "  Violent/JJ\n",
      "  crime/NN\n",
      "  rates/NNS\n",
      "  have/VBP\n",
      "  fallen/VBN\n",
      "  to/TO\n",
      "  their/PRP$\n",
      "  lowest/JJS\n",
      "  levels/NNS\n",
      "  since/IN\n",
      "  the/DT\n",
      "  1970s/CD\n",
      "  ./.)\n",
      "(S\n",
      "  Welfare/NN\n",
      "  cases/NNS\n",
      "  have/VBP\n",
      "  dropped/VBN\n",
      "  by/IN\n",
      "  more/JJR\n",
      "  than/IN\n",
      "  half/NN\n",
      "  over/IN\n",
      "  the/DT\n",
      "  past/JJ\n",
      "  decade/NN\n",
      "  ./.)\n",
      "(S\n",
      "  Drug/NN\n",
      "  use/NN\n",
      "  among/IN\n",
      "  youth/NN\n",
      "  is/VBZ\n",
      "  down/RB\n",
      "  19/CD\n",
      "  percent/NN\n",
      "  since/IN\n",
      "  2001/CD\n",
      "  ./.)\n",
      "(S\n",
      "  There/EX\n",
      "  are/VBP\n",
      "  fewer/JJR\n",
      "  abortions/NNS\n",
      "  in/IN\n",
      "  (Chunk America/NNP)\n",
      "  than/IN\n",
      "  at/IN\n",
      "  any/DT\n",
      "  point/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  last/JJ\n",
      "  three/CD\n",
      "  decades/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  the/DT\n",
      "  number/NN\n",
      "  of/IN\n",
      "  children/NNS\n",
      "  born/VBN\n",
      "  to/TO\n",
      "  teenage/VB\n",
      "  mothers/NNS\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  falling/VBG\n",
      "  for/IN\n",
      "  a/DT\n",
      "  dozen/NN\n",
      "  years/NNS\n",
      "  in/IN\n",
      "  a/DT\n",
      "  row/NN\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  These/DT\n",
      "  gains/NNS\n",
      "  are/VBP\n",
      "  evidence/NN\n",
      "  of/IN\n",
      "  a/DT\n",
      "  quiet/JJ\n",
      "  transformation/NN\n",
      "  --/:\n",
      "  a/DT\n",
      "  revolution/NN\n",
      "  of/IN\n",
      "  conscience/NN\n",
      "  ,/,\n",
      "  in/IN\n",
      "  which/WDT\n",
      "  a/DT\n",
      "  rising/VBG\n",
      "  generation/NN\n",
      "  is/VBZ\n",
      "  finding/VBG\n",
      "  that/IN\n",
      "  a/DT\n",
      "  life/NN\n",
      "  of/IN\n",
      "  personal/JJ\n",
      "  responsibility/NN\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  life/NN\n",
      "  of/IN\n",
      "  fulfillment/NN\n",
      "  ./.)\n",
      "(S (Chunk Government/NNP) has/VBZ played/VBN a/DT role/NN ./.)\n",
      "(S\n",
      "  (Chunk Wise/NNP)\n",
      "  policies/NNS\n",
      "  ,/,\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  welfare/NN\n",
      "  reform/NN\n",
      "  and/CC\n",
      "  drug/NN\n",
      "  education/NN\n",
      "  and/CC\n",
      "  support/NN\n",
      "  for/IN\n",
      "  abstinence/NN\n",
      "  and/CC\n",
      "  adoption/NN\n",
      "  have/VBP\n",
      "  made/VBN\n",
      "  a/DT\n",
      "  difference/NN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  character/NN\n",
      "  of/IN\n",
      "  our/PRP$\n",
      "  country/NN\n",
      "  ./.)\n",
      "(S\n",
      "  And/CC\n",
      "  everyone/NN\n",
      "  here/RB\n",
      "  tonight/RB\n",
      "  ,/,\n",
      "  (Chunk Democrat/NNP)\n",
      "  and/CC\n",
      "  (Chunk Republican/NNP)\n",
      "  ,/,\n",
      "  has/VBZ\n",
      "  a/DT\n",
      "  right/NN\n",
      "  to/TO\n",
      "  be/VB\n",
      "  proud/JJ\n",
      "  of/IN\n",
      "  this/DT\n",
      "  record/NN\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  Yet/RB\n",
      "  many/JJ\n",
      "  Americans/NNPS\n",
      "  ,/,\n",
      "  especially/RB\n",
      "  parents/NNS\n",
      "  ,/,\n",
      "  still/RB\n",
      "  have/VBP\n",
      "  deep/JJ\n",
      "  concerns/NNS\n",
      "  about/IN\n",
      "  the/DT\n",
      "  direction/NN\n",
      "  of/IN\n",
      "  our/PRP$\n",
      "  culture/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  the/DT\n",
      "  health/NN\n",
      "  of/IN\n",
      "  our/PRP$\n",
      "  most/JJS\n",
      "  basic/JJ\n",
      "  institutions/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  They/PRP\n",
      "  're/VBP\n",
      "  concerned/VBN\n",
      "  about/IN\n",
      "  unethical/JJ\n",
      "  conduct/NN\n",
      "  by/IN\n",
      "  public/JJ\n",
      "  officials/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  discouraged/VBN\n",
      "  by/IN\n",
      "  activist/NN\n",
      "  courts/NNS\n",
      "  that/WDT\n",
      "  try/VBP\n",
      "  to/TO\n",
      "  redefine/VB\n",
      "  marriage/NN\n",
      "  ./.)\n",
      "(S\n",
      "  They/PRP\n",
      "  worry/VBP\n",
      "  about/IN\n",
      "  children/NNS\n",
      "  in/IN\n",
      "  our/PRP$\n",
      "  society/NN\n",
      "  who/WP\n",
      "  need/VBP\n",
      "  direction/NN\n",
      "  and/CC\n",
      "  love/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  about/IN\n",
      "  fellow/JJ\n",
      "  citizens/NNS\n",
      "  still/RB\n",
      "  displaced/VBN\n",
      "  by/IN\n",
      "  natural/JJ\n",
      "  disaster/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  about/IN\n",
      "  suffering/VBG\n",
      "  caused/VBN\n",
      "  by/IN\n",
      "  treatable/JJ\n",
      "  diseases/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  As/IN\n",
      "  we/PRP\n",
      "  look/VBP\n",
      "  at/IN\n",
      "  these/DT\n",
      "  challenges/NNS\n",
      "  ,/,\n",
      "  we/PRP\n",
      "  must/MD\n",
      "  never/RB\n",
      "  give/VB\n",
      "  in/IN\n",
      "  to/TO\n",
      "  the/DT\n",
      "  belief/NN\n",
      "  that/IN\n",
      "  (Chunk America/NNP)\n",
      "  is/VBZ\n",
      "  in/IN\n",
      "  decline/NN\n",
      "  ,/,\n",
      "  or/CC\n",
      "  that/IN\n",
      "  our/PRP$\n",
      "  culture/NN\n",
      "  is/VBZ\n",
      "  doomed/VBN\n",
      "  to/TO\n",
      "  unravel/VB\n",
      "  ./.)\n",
      "(S\n",
      "  The/DT\n",
      "  American/JJ\n",
      "  people/NNS\n",
      "  know/VBP\n",
      "  better/JJR\n",
      "  than/IN\n",
      "  that/DT\n",
      "  ./.)\n",
      "(S\n",
      "  We/PRP\n",
      "  have/VBP\n",
      "  proven/VBN\n",
      "  the/DT\n",
      "  pessimists/NNS\n",
      "  wrong/JJ\n",
      "  before/RB\n",
      "  --/:\n",
      "  and/CC\n",
      "  we/PRP\n",
      "  will/MD\n",
      "  do/VB\n",
      "  it/PRP\n",
      "  again/RB\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  A/DT\n",
      "  hopeful/JJ\n",
      "  society/NN\n",
      "  depends/VBZ\n",
      "  on/IN\n",
      "  courts/NNS\n",
      "  that/IN\n",
      "  deliver/VBP\n",
      "  equal/JJ\n",
      "  justice/NN\n",
      "  under/IN\n",
      "  the/DT\n",
      "  law/NN\n",
      "  ./.)\n",
      "(S\n",
      "  The/DT\n",
      "  (Chunk Supreme/NNP Court/NNP)\n",
      "  now/RB\n",
      "  has/VBZ\n",
      "  two/CD\n",
      "  superb/JJ\n",
      "  new/JJ\n",
      "  members/NNS\n",
      "  --/:\n",
      "  new/JJ\n",
      "  members/NNS\n",
      "  on/IN\n",
      "  its/PRP$\n",
      "  bench/NN\n",
      "  :/:\n",
      "  Chief/JJ\n",
      "  (Chunk Justice/NNP John/NNP Roberts/NNP)\n",
      "  and/CC\n",
      "  (Chunk Justice/NNP Sam/NNP Alito/NNP)\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  I/PRP\n",
      "  thank/VBD\n",
      "  the/DT\n",
      "  (Chunk Senate/NNP)\n",
      "  for/IN\n",
      "  confirming/VBG\n",
      "  both/DT\n",
      "  of/IN\n",
      "  them/PRP\n",
      "  ./.)\n",
      "(S\n",
      "  I/PRP\n",
      "  will/MD\n",
      "  continue/VB\n",
      "  to/TO\n",
      "  nominate/VB\n",
      "  men/NNS\n",
      "  and/CC\n",
      "  women/NNS\n",
      "  who/WP\n",
      "  understand/VBP\n",
      "  that/IN\n",
      "  judges/NNS\n",
      "  must/MD\n",
      "  be/VB\n",
      "  servants/NNS\n",
      "  of/IN\n",
      "  the/DT\n",
      "  law/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  not/RB\n",
      "  legislate/VB\n",
      "  from/IN\n",
      "  the/DT\n",
      "  bench/NN\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  Today/NN\n",
      "  marks/VBZ\n",
      "  the/DT\n",
      "  official/JJ\n",
      "  retirement/NN\n",
      "  of/IN\n",
      "  a/DT\n",
      "  very/RB\n",
      "  special/JJ\n",
      "  (Chunk American/NNP)\n",
      "  ./.)\n",
      "(S\n",
      "  For/IN\n",
      "  24/CD\n",
      "  years/NNS\n",
      "  of/IN\n",
      "  faithful/JJ\n",
      "  service/NN\n",
      "  to/TO\n",
      "  our/PRP$\n",
      "  nation/NN\n",
      "  ,/,\n",
      "  the/DT\n",
      "  (Chunk United/NNP)\n",
      "  States/NNPS\n",
      "  is/VBZ\n",
      "  grateful/JJ\n",
      "  to/TO\n",
      "  (Chunk Justice/NNP Sandra/NNP Day/NNP O'Connor/NNP)\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  A/DT\n",
      "  hopeful/JJ\n",
      "  society/NN\n",
      "  has/VBZ\n",
      "  institutions/NNS\n",
      "  of/IN\n",
      "  science/NN\n",
      "  and/CC\n",
      "  medicine/NN\n",
      "  that/WDT\n",
      "  do/VBP\n",
      "  not/RB\n",
      "  cut/VB\n",
      "  ethical/JJ\n",
      "  corners/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  that/IN\n",
      "  recognize/VBP\n",
      "  the/DT\n",
      "  matchless/NN\n",
      "  value/NN\n",
      "  of/IN\n",
      "  every/DT\n",
      "  life/NN\n",
      "  ./.)\n",
      "(S\n",
      "  (Chunk Tonight/NNP)\n",
      "  I/PRP\n",
      "  ask/VBP\n",
      "  you/PRP\n",
      "  to/TO\n",
      "  pass/VB\n",
      "  legislation/NN\n",
      "  to/TO\n",
      "  prohibit/VB\n",
      "  the/DT\n",
      "  most/RBS\n",
      "  egregious/JJ\n",
      "  abuses/NNS\n",
      "  of/IN\n",
      "  medical/JJ\n",
      "  research/NN\n",
      "  :/:\n",
      "  human/JJ\n",
      "  cloning/VBG\n",
      "  in/IN\n",
      "  all/DT\n",
      "  its/PRP$\n",
      "  forms/NNS\n",
      "  ,/,\n",
      "  creating/VBG\n",
      "  or/CC\n",
      "  implanting/VBG\n",
      "  embryos/NN\n",
      "  for/IN\n",
      "  experiments/NNS\n",
      "  ,/,\n",
      "  creating/VBG\n",
      "  human-animal/JJ\n",
      "  hybrids/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  buying/NN\n",
      "  ,/,\n",
      "  selling/NN\n",
      "  ,/,\n",
      "  or/CC\n",
      "  patenting/VBG\n",
      "  human/JJ\n",
      "  embryos/NN\n",
      "  ./.)\n",
      "(S\n",
      "  (Chunk Human/NNP life/NN)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  gift/NN\n",
      "  from/IN\n",
      "  our/PRP$\n",
      "  (Chunk Creator/NNP)\n",
      "  --/:\n",
      "  and/CC\n",
      "  that/IN\n",
      "  gift/NN\n",
      "  should/MD\n",
      "  never/RB\n",
      "  be/VB\n",
      "  discarded/VBN\n",
      "  ,/,\n",
      "  devalued/VBD\n",
      "  or/CC\n",
      "  put/VB\n",
      "  up/RP\n",
      "  for/IN\n",
      "  sale/NN\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  A/DT\n",
      "  hopeful/JJ\n",
      "  society/NN\n",
      "  expects/VBZ\n",
      "  elected/VBN\n",
      "  officials/NNS\n",
      "  to/TO\n",
      "  uphold/VB\n",
      "  the/DT\n",
      "  public/JJ\n",
      "  trust/NN\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  Honorable/JJ\n",
      "  people/NNS\n",
      "  in/IN\n",
      "  both/DT\n",
      "  parties/NNS\n",
      "  are/VBP\n",
      "  working/VBG\n",
      "  on/IN\n",
      "  reforms/NNS\n",
      "  to/TO\n",
      "  strengthen/VB\n",
      "  the/DT\n",
      "  ethical/JJ\n",
      "  standards/NNS\n",
      "  of/IN\n",
      "  (Chunk Washington/NNP)\n",
      "  --/:\n",
      "  I/PRP\n",
      "  support/VBP\n",
      "  your/PRP$\n",
      "  efforts/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  Each/DT\n",
      "  of/IN\n",
      "  us/PRP\n",
      "  has/VBZ\n",
      "  made/VBN\n",
      "  a/DT\n",
      "  pledge/NN\n",
      "  to/TO\n",
      "  be/VB\n",
      "  worthy/JJ\n",
      "  of/IN\n",
      "  public/JJ\n",
      "  responsibility/NN\n",
      "  --/:\n",
      "  and/CC\n",
      "  that/DT\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  pledge/NN\n",
      "  we/PRP\n",
      "  must/MD\n",
      "  never/RB\n",
      "  forget/VB\n",
      "  ,/,\n",
      "  never/RB\n",
      "  dismiss/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  never/RB\n",
      "  betray/NN\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  As/IN\n",
      "  we/PRP\n",
      "  renew/VBP\n",
      "  the/DT\n",
      "  promise/NN\n",
      "  of/IN\n",
      "  our/PRP$\n",
      "  institutions/NNS\n",
      "  ,/,\n",
      "  let/VB\n",
      "  us/PRP\n",
      "  also/RB\n",
      "  show/VBP\n",
      "  the/DT\n",
      "  character/NN\n",
      "  of/IN\n",
      "  (Chunk America/NNP)\n",
      "  in/IN\n",
      "  our/PRP$\n",
      "  compassion/NN\n",
      "  and/CC\n",
      "  care/NN\n",
      "  for/IN\n",
      "  one/CD\n",
      "  another/DT\n",
      "  ./.)\n",
      "(S\n",
      "  A/DT\n",
      "  hopeful/JJ\n",
      "  society/NN\n",
      "  gives/VBZ\n",
      "  special/JJ\n",
      "  attention/NN\n",
      "  to/TO\n",
      "  children/NNS\n",
      "  who/WP\n",
      "  lack/VBP\n",
      "  direction/NN\n",
      "  and/CC\n",
      "  love/NN\n",
      "  ./.)\n",
      "(S\n",
      "  Through/IN\n",
      "  the/DT\n",
      "  (Chunk Helping/NNP America/NNP)\n",
      "  's/POS\n",
      "  (Chunk Youth/NNP Initiative/NNP)\n",
      "  ,/,\n",
      "  we/PRP\n",
      "  are/VBP\n",
      "  encouraging/VBG\n",
      "  caring/VBG\n",
      "  adults/NNS\n",
      "  to/TO\n",
      "  get/VB\n",
      "  involved/VBN\n",
      "  in/IN\n",
      "  the/DT\n",
      "  life/NN\n",
      "  of/IN\n",
      "  a/DT\n",
      "  child/NN\n",
      "  --/:\n",
      "  and/CC\n",
      "  this/DT\n",
      "  good/JJ\n",
      "  work/NN\n",
      "  is/VBZ\n",
      "  being/VBG\n",
      "  led/VBN\n",
      "  by/IN\n",
      "  our/PRP$\n",
      "  (Chunk First/NNP Lady/NNP)\n",
      "  ,/,\n",
      "  (Chunk Laura/NNP Bush/NNP)\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  This/DT\n",
      "  year/NN\n",
      "  we/PRP\n",
      "  will/MD\n",
      "  add/VB\n",
      "  resources/NNS\n",
      "  to/TO\n",
      "  encourage/VB\n",
      "  young/JJ\n",
      "  people/NNS\n",
      "  to/TO\n",
      "  stay/VB\n",
      "  in/IN\n",
      "  school/NN\n",
      "  ,/,\n",
      "  so/RB\n",
      "  more/JJR\n",
      "  of/IN\n",
      "  (Chunk America/NNP)\n",
      "  's/POS\n",
      "  youth/NN\n",
      "  can/MD\n",
      "  raise/VB\n",
      "  their/PRP$\n",
      "  sights/NNS\n",
      "  and/CC\n",
      "  achieve/VBP\n",
      "  their/PRP$\n",
      "  dreams/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  A/DT\n",
      "  hopeful/JJ\n",
      "  society/NN\n",
      "  comes/VBZ\n",
      "  to/TO\n",
      "  the/DT\n",
      "  aid/NN\n",
      "  of/IN\n",
      "  fellow/JJ\n",
      "  citizens/NNS\n",
      "  in/IN\n",
      "  times/NNS\n",
      "  of/IN\n",
      "  suffering/NN\n",
      "  and/CC\n",
      "  emergency/NN\n",
      "  --/:\n",
      "  and/CC\n",
      "  stays/NNS\n",
      "  at/IN\n",
      "  it/PRP\n",
      "  until/IN\n",
      "  they/PRP\n",
      "  're/VBP\n",
      "  back/RB\n",
      "  on/IN\n",
      "  their/PRP$\n",
      "  feet/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  So/RB\n",
      "  far/RB\n",
      "  the/DT\n",
      "  federal/JJ\n",
      "  government/NN\n",
      "  has/VBZ\n",
      "  committed/VBN\n",
      "  $/$\n",
      "  85/CD\n",
      "  billion/CD\n",
      "  to/TO\n",
      "  the/DT\n",
      "  people/NNS\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (Chunk Gulf/NNP Coast/NNP)\n",
      "  and/CC\n",
      "  (Chunk New/NNP Orleans/NNP)\n",
      "  ./.)\n",
      "(S\n",
      "  We/PRP\n",
      "  're/VBP\n",
      "  removing/VBG\n",
      "  debris/NN\n",
      "  and/CC\n",
      "  repairing/NN\n",
      "  highways/NNS\n",
      "  and/CC\n",
      "  rebuilding/VBG\n",
      "  stronger/JJR\n",
      "  levees/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  We/PRP\n",
      "  're/VBP\n",
      "  providing/VBG\n",
      "  business/NN\n",
      "  loans/NNS\n",
      "  and/CC\n",
      "  housing/NN\n",
      "  assistance/NN\n",
      "  ./.)\n",
      "(S\n",
      "  Yet/RB\n",
      "  as/IN\n",
      "  we/PRP\n",
      "  meet/VBP\n",
      "  these/DT\n",
      "  immediate/JJ\n",
      "  needs/NNS\n",
      "  ,/,\n",
      "  we/PRP\n",
      "  must/MD\n",
      "  also/RB\n",
      "  address/VB\n",
      "  deeper/JJR\n",
      "  challenges/NNS\n",
      "  that/WDT\n",
      "  existed/VBD\n",
      "  before/IN\n",
      "  the/DT\n",
      "  storm/NN\n",
      "  arrived/VBD\n",
      "  ./.)\n",
      "(S\n",
      "  In/IN\n",
      "  (Chunk New/NNP Orleans/NNP)\n",
      "  and/CC\n",
      "  in/IN\n",
      "  other/JJ\n",
      "  places/NNS\n",
      "  ,/,\n",
      "  many/JJ\n",
      "  of/IN\n",
      "  our/PRP$\n",
      "  fellow/JJ\n",
      "  citizens/NNS\n",
      "  have/VBP\n",
      "  felt/VBN\n",
      "  excluded/VBN\n",
      "  from/IN\n",
      "  the/DT\n",
      "  promise/NN\n",
      "  of/IN\n",
      "  our/PRP$\n",
      "  country/NN\n",
      "  ./.)\n",
      "(S\n",
      "  The/DT\n",
      "  answer/NN\n",
      "  is/VBZ\n",
      "  not/RB\n",
      "  only/RB\n",
      "  temporary/JJ\n",
      "  relief/NN\n",
      "  ,/,\n",
      "  but/CC\n",
      "  schools/NNS\n",
      "  that/WDT\n",
      "  teach/VBP\n",
      "  every/DT\n",
      "  child/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  job/NN\n",
      "  skills/NNS\n",
      "  that/IN\n",
      "  bring/VBG\n",
      "  upward/JJ\n",
      "  mobility/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  more/JJR\n",
      "  opportunities/NNS\n",
      "  to/TO\n",
      "  own/VB\n",
      "  a/DT\n",
      "  home/NN\n",
      "  and/CC\n",
      "  start/VB\n",
      "  a/DT\n",
      "  business/NN\n",
      "  ./.)\n",
      "(S\n",
      "  As/IN\n",
      "  we/PRP\n",
      "  recover/VBP\n",
      "  from/IN\n",
      "  a/DT\n",
      "  disaster/NN\n",
      "  ,/,\n",
      "  let/VB\n",
      "  us/PRP\n",
      "  also/RB\n",
      "  work/NN\n",
      "  for/IN\n",
      "  the/DT\n",
      "  day/NN\n",
      "  when/WRB\n",
      "  all/DT\n",
      "  Americans/NNPS\n",
      "  are/VBP\n",
      "  protected/VBN\n",
      "  by/IN\n",
      "  justice/NN\n",
      "  ,/,\n",
      "  equal/JJ\n",
      "  in/IN\n",
      "  hope/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  rich/JJ\n",
      "  in/IN\n",
      "  opportunity/NN\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  A/DT\n",
      "  hopeful/JJ\n",
      "  society/NN\n",
      "  acts/NNS\n",
      "  boldly/RB\n",
      "  to/TO\n",
      "  fight/VB\n",
      "  diseases/NNS\n",
      "  like/IN\n",
      "  (Chunk HIV/AIDS/NNP)\n",
      "  ,/,\n",
      "  which/WDT\n",
      "  can/MD\n",
      "  be/VB\n",
      "  prevented/VBN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  treated/VBD\n",
      "  ,/,\n",
      "  and/CC\n",
      "  defeated/VBD\n",
      "  ./.)\n",
      "(S\n",
      "  More/JJR\n",
      "  than/IN\n",
      "  a/DT\n",
      "  million/CD\n",
      "  Americans/NNPS\n",
      "  live/VBP\n",
      "  with/IN\n",
      "  (Chunk HIV/NNP)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  half/NN\n",
      "  of/IN\n",
      "  all/DT\n",
      "  (Chunk AIDS/NNP)\n",
      "  cases/NNS\n",
      "  occur/VBP\n",
      "  among/IN\n",
      "  African/JJ\n",
      "  Americans/NNPS\n",
      "  ./.)\n",
      "(S\n",
      "  I/PRP\n",
      "  (Chunk ask/VBP Congress/NNP)\n",
      "  to/TO\n",
      "  reform/VB\n",
      "  and/CC\n",
      "  reauthorize/VB\n",
      "  the/DT\n",
      "  (Chunk Ryan/NNP White/NNP Act/NNP)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  provide/VB\n",
      "  new/JJ\n",
      "  funding/NN\n",
      "  to/TO\n",
      "  states/NNS\n",
      "  ,/,\n",
      "  so/IN\n",
      "  we/PRP\n",
      "  end/VBP\n",
      "  the/DT\n",
      "  waiting/NN\n",
      "  lists/NNS\n",
      "  for/IN\n",
      "  (Chunk AIDS/NNP)\n",
      "  medicines/NNS\n",
      "  in/IN\n",
      "  (Chunk America/NNP)\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  We/PRP\n",
      "  will/MD\n",
      "  also/RB\n",
      "  lead/VB\n",
      "  a/DT\n",
      "  nationwide/JJ\n",
      "  effort/NN\n",
      "  ,/,\n",
      "  working/VBG\n",
      "  closely/RB\n",
      "  with/IN\n",
      "  African/JJ\n",
      "  American/JJ\n",
      "  churches/NNS\n",
      "  and/CC\n",
      "  faith-based/JJ\n",
      "  groups/NNS\n",
      "  ,/,\n",
      "  to/TO\n",
      "  deliver/VB\n",
      "  rapid/JJ\n",
      "  (Chunk HIV/NNP)\n",
      "  tests/NNS\n",
      "  to/TO\n",
      "  millions/NNS\n",
      "  ,/,\n",
      "  end/VBP\n",
      "  the/DT\n",
      "  stigma/NN\n",
      "  of/IN\n",
      "  (Chunk AIDS/NNP)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  come/VB\n",
      "  closer/JJR\n",
      "  to/TO\n",
      "  the/DT\n",
      "  day/NN\n",
      "  when/WRB\n",
      "  there/EX\n",
      "  are/VBP\n",
      "  no/DT\n",
      "  new/JJ\n",
      "  infections/NNS\n",
      "  in/IN\n",
      "  (Chunk America/NNP)\n",
      "  ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n",
      "(S\n",
      "  (Chunk Fellow/NNP)\n",
      "  citizens/NNS\n",
      "  ,/,\n",
      "  we/PRP\n",
      "  've/VBP\n",
      "  been/VBN\n",
      "  called/VBN\n",
      "  to/TO\n",
      "  leadership/NN\n",
      "  in/IN\n",
      "  a/DT\n",
      "  period/NN\n",
      "  of/IN\n",
      "  consequence/NN\n",
      "  ./.)\n",
      "(S\n",
      "  We/PRP\n",
      "  've/VBP\n",
      "  entered/VBN\n",
      "  a/DT\n",
      "  great/JJ\n",
      "  ideological/JJ\n",
      "  conflict/NN\n",
      "  we/PRP\n",
      "  did/VBD\n",
      "  nothing/NN\n",
      "  to/TO\n",
      "  invite/VB\n",
      "  ./.)\n",
      "(S\n",
      "  We/PRP\n",
      "  see/VBP\n",
      "  great/JJ\n",
      "  changes/NNS\n",
      "  in/IN\n",
      "  science/NN\n",
      "  and/CC\n",
      "  commerce/NN\n",
      "  that/WDT\n",
      "  will/MD\n",
      "  influence/VB\n",
      "  all/DT\n",
      "  our/PRP$\n",
      "  lives/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  Sometimes/RB\n",
      "  it/PRP\n",
      "  can/MD\n",
      "  seem/VB\n",
      "  that/DT\n",
      "  history/NN\n",
      "  is/VBZ\n",
      "  turning/VBG\n",
      "  in/IN\n",
      "  a/DT\n",
      "  wide/JJ\n",
      "  arc/NN\n",
      "  ,/,\n",
      "  toward/IN\n",
      "  an/DT\n",
      "  unknown/JJ\n",
      "  shore/NN\n",
      "  ./.)\n",
      "(S\n",
      "  Yet/CC\n",
      "  the/DT\n",
      "  destination/NN\n",
      "  of/IN\n",
      "  history/NN\n",
      "  is/VBZ\n",
      "  determined/VBN\n",
      "  by/IN\n",
      "  human/JJ\n",
      "  action/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  every/DT\n",
      "  great/JJ\n",
      "  movement/NN\n",
      "  of/IN\n",
      "  history/NN\n",
      "  comes/VBZ\n",
      "  to/TO\n",
      "  a/DT\n",
      "  point/NN\n",
      "  of/IN\n",
      "  choosing/NN\n",
      "  ./.)\n",
      "(S\n",
      "  (Chunk Lincoln/NNP)\n",
      "  could/MD\n",
      "  have/VB\n",
      "  accepted/VBN\n",
      "  peace/NN\n",
      "  at/IN\n",
      "  the/DT\n",
      "  cost/NN\n",
      "  of/IN\n",
      "  disunity/NN\n",
      "  and/CC\n",
      "  continued/JJ\n",
      "  slavery/NN\n",
      "  ./.)\n",
      "(S\n",
      "  (Chunk Martin/NNP Luther/NNP King/NNP)\n",
      "  could/MD\n",
      "  have/VB\n",
      "  stopped/VBN\n",
      "  at/IN\n",
      "  (Chunk Birmingham/NNP)\n",
      "  or/CC\n",
      "  at/IN\n",
      "  (Chunk Selma/NNP)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  achieved/VBD\n",
      "  only/RB\n",
      "  half/PDT\n",
      "  a/DT\n",
      "  victory/NN\n",
      "  over/IN\n",
      "  segregation/NN\n",
      "  ./.)\n",
      "(S\n",
      "  The/DT\n",
      "  (Chunk United/NNP)\n",
      "  States/NNPS\n",
      "  could/MD\n",
      "  have/VB\n",
      "  accepted/VBN\n",
      "  the/DT\n",
      "  permanent/JJ\n",
      "  division/NN\n",
      "  of/IN\n",
      "  (Chunk Europe/NNP)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  been/VBN\n",
      "  complicit/NNS\n",
      "  in/IN\n",
      "  the/DT\n",
      "  oppression/NN\n",
      "  of/IN\n",
      "  others/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  Today/NN\n",
      "  ,/,\n",
      "  having/VBG\n",
      "  come/VBN\n",
      "  far/RB\n",
      "  in/IN\n",
      "  our/PRP$\n",
      "  own/JJ\n",
      "  historical/JJ\n",
      "  journey/NN\n",
      "  ,/,\n",
      "  we/PRP\n",
      "  must/MD\n",
      "  decide/VB\n",
      "  :/:\n",
      "  Will/MD\n",
      "  we/PRP\n",
      "  turn/VB\n",
      "  back/RP\n",
      "  ,/,\n",
      "  or/CC\n",
      "  finish/VB\n",
      "  well/RB\n",
      "  ?/.)\n",
      "(S\n",
      "  Before/IN\n",
      "  history/NN\n",
      "  is/VBZ\n",
      "  written/VBN\n",
      "  down/RP\n",
      "  in/IN\n",
      "  books/NNS\n",
      "  ,/,\n",
      "  it/PRP\n",
      "  is/VBZ\n",
      "  written/VBN\n",
      "  in/IN\n",
      "  courage/NN\n",
      "  ./.)\n",
      "(S\n",
      "  Like/IN\n",
      "  Americans/NNPS\n",
      "  before/IN\n",
      "  us/PRP\n",
      "  ,/,\n",
      "  we/PRP\n",
      "  will/MD\n",
      "  show/VB\n",
      "  that/DT\n",
      "  courage/NN\n",
      "  and/CC\n",
      "  we/PRP\n",
      "  will/MD\n",
      "  finish/VB\n",
      "  well/RB\n",
      "  ./.)\n",
      "(S We/PRP will/MD lead/VB freedom/NN 's/POS advance/NN ./.)\n",
      "(S\n",
      "  We/PRP\n",
      "  will/MD\n",
      "  compete/VB\n",
      "  and/CC\n",
      "  excel/VB\n",
      "  in/IN\n",
      "  the/DT\n",
      "  global/JJ\n",
      "  economy/NN\n",
      "  ./.)\n",
      "(S\n",
      "  We/PRP\n",
      "  will/MD\n",
      "  renew/VB\n",
      "  the/DT\n",
      "  defining/VBG\n",
      "  moral/JJ\n",
      "  commitments/NNS\n",
      "  of/IN\n",
      "  this/DT\n",
      "  land/NN\n",
      "  ./.)\n",
      "(S\n",
      "  And/CC\n",
      "  so/RB\n",
      "  we/PRP\n",
      "  move/VBP\n",
      "  forward/RB\n",
      "  --/:\n",
      "  optimistic/JJ\n",
      "  about/IN\n",
      "  our/PRP$\n",
      "  country/NN\n",
      "  ,/,\n",
      "  faithful/JJ\n",
      "  to/TO\n",
      "  its/PRP$\n",
      "  cause/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  confident/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  victories/NNS\n",
      "  to/TO\n",
      "  come/VB\n",
      "  ./.)\n",
      "(S (Chunk May/NNP God/NNP bless/NN) (Chunk America/NNP) ./.)\n",
      "(S (/( (Chunk Applause/NNP) ./. )/))\n"
     ]
    }
   ],
   "source": [
    "# Part 5. Chunking\n",
    "#Creates tuples with the word and the parts of speech. \n",
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer #Unsupervised learning tokenizer.\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try: \n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            \n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
    "\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "\n",
    "            print(chunked)\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8531e7045081>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mprocess_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-8531e7045081>\u001b[0m in \u001b[0;36mprocess_content\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mchunked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchunkParser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mchunked\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python36-32\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    748\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdraw_trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m         \u001b[0mdraw_trees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpretty_print\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighlight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python36-32\\lib\\site-packages\\nltk\\draw\\tree.py\u001b[0m in \u001b[0;36mdraw_trees\u001b[1;34m(*trees)\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m     \"\"\"\n\u001b[1;32m-> 1008\u001b[1;33m     \u001b[0mTreeView\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python36-32\\lib\\site-packages\\nltk\\draw\\tree.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0min_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python36-32\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1281\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m         \u001b[1;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1283\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1284\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m         \u001b[1;34m\"\"\"Quit the Tcl interpreter. All widgets will be destroyed.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Part 6. Chinking\n",
    "#Creates tuples with the word and the parts of speech. \n",
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer #Unsupervised learning tokenizer.\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try: \n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            \n",
    "            chunkGram = r\"\"\"Chunk: {<.*>+}\n",
    "                                    }<VB.?|IN|DT|TO>+{\"\"\"\n",
    "\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "\n",
    "            chunked.draw()\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e8b86f19027e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mprocess_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-e8b86f19027e>\u001b[0m in \u001b[0;36mprocess_content\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mnameEnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mne_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mnameEnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python36-32\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    748\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdraw_trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m         \u001b[0mdraw_trees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpretty_print\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhighlight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python36-32\\lib\\site-packages\\nltk\\draw\\tree.py\u001b[0m in \u001b[0;36mdraw_trees\u001b[1;34m(*trees)\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m     \"\"\"\n\u001b[1;32m-> 1008\u001b[1;33m     \u001b[0mTreeView\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python36-32\\lib\\site-packages\\nltk\\draw\\tree.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0min_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Python36-32\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1281\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m         \u001b[1;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1283\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1284\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m         \u001b[1;34m\"\"\"Quit the Tcl interpreter. All widgets will be destroyed.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Part 7. Name Entity Recognotion\n",
    "#Creates tuples with the word and the parts of speech. \n",
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer #Unsupervised learning tokenizer.\n",
    "\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "def process_content():\n",
    "    try: \n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "\n",
    "            nameEnt = nltk.ne_chunk(tagged, binary= True)\n",
    "\n",
    "            nameEnt.draw()\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "         \n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cat\ncactus\ngoose\nrock\npython\ngood\nbest\n"
     ]
    }
   ],
   "source": [
    "# Part 8  - Lemmatizing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words_to_lemmatize = ['cats', 'cacti', 'geese', 'rocks', 'python']\n",
    "\n",
    "for word in words_to_lemmatize:\n",
    "    print(lemmatizer.lemmatize(word))\n",
    "\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\")) #Adjetive\n",
    "print(lemmatizer.lemmatize(\"best\", pos=\"a\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['1:5 And God called the light Day, and the darkness he called Night.', 'And the evening and the morning were the first day.', '1:6 And God said, Let there be a firmament in the midst of the waters,\\nand let it divide the waters from the waters.', '1:7 And God made the firmament, and divided the waters which were\\nunder the firmament from the waters which were above the firmament:\\nand it was so.', '1:8 And God called the firmament Heaven.', 'And the evening and the\\nmorning were the second day.', '1:9 And God said, Let the waters under the heaven be gathered together\\nunto one place, and let the dry land appear: and it was so.', '1:10 And God called the dry land Earth; and the gathering together of\\nthe waters called he Seas: and God saw that it was good.', '1:11 And God said, Let the earth bring forth grass, the herb yielding\\nseed, and the fruit tree yielding fruit after his kind, whose seed is\\nin itself, upon the earth: and it was so.', '1:12 And the earth brought forth grass, and herb yielding seed after\\nhis kind, and the tree yielding fruit, whose seed was in itself, after\\nhis kind: and God saw that it was good.']\n"
     ]
    }
   ],
   "source": [
    "# Part 9 - NLTK Corpora\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sample = gutenberg.raw(\"bible-kjv.txt\")\n",
    "\n",
    "tok = sent_tokenize(sample)\n",
    "\n",
    "print(tok[5:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "plan.n.01\nplan\na series of steps to be carried out or goals to be accomplished\n['they drew up a six-step plan', 'they discussed plans for a new bond issue']\n{'effective', 'skillful', 'honorable', 'right', 'in_force', 'upright', 'sound', 'secure', 'just', 'unspoiled', 'estimable', 'near', 'well', 'respectable', 'unspoilt', 'undecomposed', 'goodness', 'skilful', 'adept', 'good', 'commodity', 'beneficial', 'full', 'soundly', 'expert', 'thoroughly', 'safe', 'ripe', 'proficient', 'dear', 'trade_good', 'dependable', 'practiced', 'in_effect', 'salutary', 'serious', 'honest'}\n{'evil', 'evilness', 'ill', 'bad', 'badness'}\n0.9090909090909091\n0.6956521739130435\n0.32\n"
     ]
    }
   ],
   "source": [
    "# Part 10 - WordNet\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "syns = wordnet.synsets(\"program\")\n",
    "\n",
    "#synset\n",
    "print(syns[0].name())\n",
    "\n",
    "#Word\n",
    "print(syns[0].lemmas()[0].name())\n",
    "\n",
    "# definitions\n",
    "print(syns[0].definition())\n",
    "\n",
    "#examples\n",
    "print(syns[0].examples())\n",
    "\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print(set(synonyms))\n",
    "print(set(antonyms))\n",
    "\n",
    "#Similarity\n",
    "\n",
    "w1 = wordnet.synset(\"ship.n.01\")\n",
    "w2 = wordnet.synset(\"boat.n.01\")\n",
    "\n",
    "print(w1.wup_similarity(w2))\n",
    "\n",
    "w1 = wordnet.synset(\"ship.n.01\")\n",
    "w2 = wordnet.synset(\"car.n.01\")\n",
    "\n",
    "print(w1.wup_similarity(w2))\n",
    "\n",
    "w1 = wordnet.synset(\"ship.n.01\")\n",
    "w2 = wordnet.synset(\"cat.n.01\")\n",
    "\n",
    "print(w1.wup_similarity(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n253\n"
     ]
    }
   ],
   "source": [
    "# Part 11 Text Classification\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "            for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "print(all_words.most_common(15))\n",
    "print(all_words['stupid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-10f182d8bfcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovie_reviews\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'neg/cv000_29416.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mfeaturesets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-10f182d8bfcf>\u001b[0m in \u001b[0;36mfind_features\u001b[1;34m(document)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Part 12 Words as Features for Learning\n",
    "import nltk\n",
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "            for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n",
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:3000]\n",
    "\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = []\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "    return features\n",
    "\n",
    "print((find_features(movie_reviews.words('neg/cv000_29416.txt'))))\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.6.8 32-bit",
   "display_name": "Python 3.6.8 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "e54ed84f84407490689b4f5b6b5f659e4528824f1b5194fa37e2daa8c8e1c1a7"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}